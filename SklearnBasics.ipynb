{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage Statistique / Machine avec <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 150px; display: inline\" alt=\"Python\"/></a> & <a href=\"http://scikit-learn.org/stable/#\"><img src=\"http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" style=\"max-width: 180px; display: inline\" alt=\"Scikit-Learn\"/></a>\n",
    "**Petit résumé**: Ce notebook introduit l'utilisation de la librairie `scikit-learn` pour la modélisation et l'apprentissage. On présentara quelques fonctionnalités et des exemples de mise en oeuvre de modélisation. On vera aussi ce qu'est l'optimisation de paramètres des modèles et la compléxité. D'autres fonctionalités de `Scikit-learn` sont abordées dans un prochain notebook. \n",
    "\n",
    "**Avertissement :** C'est plutôt technique, pas de problème si vous ne comprenez pas tout directement dès la première lecture prenez le temps de le lire 'oklm' !  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "### 1.1 Scikit-learn basic \n",
    "\n",
    "Petit rappel générique de ce qu'est `scikit-learn`. \n",
    "\n",
    "- Cette librairie manipule des objets de classe `array` de `numpy` *chargés en mémoire* et donc de taille limitée par la RAM de l'ordinateur; de façon analogue R charge en RAM des objets de type `data.frame`.\n",
    "- `Scikit-learn` reconnaît quelque fois la classe `DataFrame` de `pandas`. Une variable binaire est simplement remplacée par un codage *(0,1)* mais, en présence de plusieurs modalités, traiter celles-ci comme des entiers n'a pas de sens statistique et remplacer une variable qualitative par l'ensemble des indicatrices (*dummy variables (0,1)*) de ses modalités  complique les stratégies de sélection de modèle tout en rendant inexploitable l'interprétation statistique. \n",
    "- Les implémentations en Python de certains algorithmes dans `scikit-learn` sont souvent rapide et utilisent implicitement les capacités de parallélisation.\n",
    "\n",
    "\n",
    "### 1.2 Fonctions d'apprentissage de Scikit-learn\n",
    "La communauté qui développe cette librairie est très active et la fait évoluer très rapidement.  Ne pas hésiter à consulter la [documentation](http://scikit-learn.org/stable/user_guide.html) pour des compléments. Voici une sélection de ses principales fonctionnalités en lien avec la modélisation : \n",
    "\n",
    "- Transformations (standardisation, discrétisation binaire, regroupement de modalités, imputations rudimentaires de données manquantes) , \"vectorisation\" de corpus de textes (encodage, catalogue, Tf-idf), images;\n",
    "- Modéle linéaire général avec pénalisation (ridge, lasso, elastic net...), analyse discriminante linéaire et quadratique,  $k$ plus proches voisins,  processus gaussiens, classifieur bayésien naïf, arbres de régression et classification (CART), agrégation de modèles (bagging, random forest, adaboost, gradient tree boosting), perceptron multicouche (réseau de neurones), SVM (classification, régression, détection d'atypiques...);\n",
    "- Algorithmes de validation croisée (loo, k-fold, VC stratifiée...) et sélection de modèles, optimisation sur une grille de paramètres, séparation aléatoire apprentissage et test, courbe ROC;\n",
    "- Enchaînement (*pipeline*) de traitements.\n",
    "\n",
    "En résumé, cette librairie est focalisée sur les aspects \"machine\" de l'apprentissage de données quantitatives (séries, signaux, images) volumineuses. \n",
    "\n",
    "### 1.3 Objectif \n",
    "Illustrer la mise en oeuvre de quelques fonctionnalités ainsi que apprendre à consulter la [documentation](http://scikit-learn.org/stable/user_guide.html) et ses nombreux [exemples](http://scikit-learn.org/stable/auto_examples/index.html) pour plus de détails sur les possibilités d'utilisation de `scikit-learn`. \n",
    "\n",
    "Deux jeux de données élémentaires sont utilisés, des variables explicatives qualitatives et quantitatives généralement dans un objet de la classe `DataFrame`. Pour être utilisé dans `scikit-learn` les données doivent souvent être transformées en un objet de classe `Array` de `numpy` par le  remplacement des variables qualitatives par les indicatrices de leurs modalités.  On peut aussi noterun autre ensemble de données, lui entièrement quantitatif. C'est un problème classique et simplifié de [reconnaissance de caractères](http://archive.ics.uci.edu/ml/datasets/Pen-Based+Recognition+of+Handwritten+Digits) qui est inclus dans la librairie `scikit-learn`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Extraction des échantillons\n",
    "Le travail préliminaire consiste à séparer les échantillons en une partie *apprentissage* et une autre de *test* pour estimer sans biais l'[erreur de prévision](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf). L'optimisation (biais-variance) de la complexité des modèles est réalisée en minimisant l'erreur estimée par [validation croisée](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf) $V-fold$. \n",
    "\n",
    "### 2.1 Données \"Caractères\"\n",
    "Elles sont disponibles dans la librairie `Scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
      "       ...,\n",
      "       [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "       [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
      "       [ 0.,  0., 10., ..., 12.,  1.,  0.]]), 'target': array([0, 1, 2, ..., 8, 9, 8]), 'frame': None, 'feature_names': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
      "        [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
      "        [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
      "        [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
      "        [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
      "        [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
      "        [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
      "        [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
      "        [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
      "        [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
      "        [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
      "\n",
      "       [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
      "        [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
      "        ...,\n",
      "        [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
      "        [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
      "        [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]), 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}\n"
     ]
    }
   ],
   "source": [
    "# Importations \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "%matplotlib inline\n",
    "# les données\n",
    "digits = datasets.load_digits()\n",
    "# Contenu et mode d'obtention\n",
    "print(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(digits.images, \n",
    "   digits.target))\n",
    "for index, (image, label) in  enumerate(images_and_labels[:8]):\n",
    "     plt.subplot(2, 4, index + 1)\n",
    "     plt.axis('off')\n",
    "     plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "     plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables prédictives et cible\n",
    "X=digits.data\n",
    "y=digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Données \"Titanic\"\n",
    "\n",
    "Les données sur le naufrage du Titanic sont décrites dans le calepin consacré à la librairie *pandas*. Reconstruire la table des données en lisant le fichier .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Age</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Surv Classe   Genre   Age     Prix Port\n",
       "0    0      3    male  22.0   7.2500    S\n",
       "1    1      1  female  38.0  71.2833    C\n",
       "2    1      3  female  26.0   7.9250    S\n",
       "3    1      1  female  35.0  53.1000    S\n",
       "4    0      3    male  35.0   8.0500    S"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lire les données d'apprentissage\n",
    "import pandas as pd\n",
    "path='./data/titanic/'  # si les données sont déjà dans le répertoire courant SINON metter le bon chemin \n",
    "# path='http://www.math.univ-toulouse.fr/~besse/Wikistat/data/'\n",
    "df=pd.read_csv(path+'train.csv',skiprows=1,header=None,usecols=[1,2,4,5,9,11],\n",
    "  names=[\"Surv\",\"Classe\",\"Genre\",\"Age\",\"Prix\",\"Port\"],dtype={\"Surv\":object,\"Classe\":object,\"Genre\":object,\"Port\":object})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surv      category\n",
       "Classe    category\n",
       "Genre     category\n",
       "Age        float64\n",
       "Prix       float64\n",
       "Port      category\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # dimensions\n",
    "# Redéfinir les types \n",
    "df[\"Surv\"]=pd.Categorical(df[\"Surv\"],ordered=False)\n",
    "df[\"Classe\"]=pd.Categorical(df[\"Classe\"],ordered=False)\n",
    "df[\"Genre\"]=pd.Categorical(df[\"Genre\"],ordered=False)\n",
    "df[\"Port\"]=pd.Categorical(df[\"Port\"],ordered=False)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surv      891\n",
       "Classe    891\n",
       "Genre     891\n",
       "Age       714\n",
       "Prix      891\n",
       "Port      889\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation des valeurs manquantes\n",
    "df[\"Age\"]=df[\"Age\"].fillna(df[\"Age\"].median())\n",
    "df.Port=df[\"Port\"].fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv</th>\n",
       "      <th>Classe</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Age</th>\n",
       "      <th>Prix</th>\n",
       "      <th>Port</th>\n",
       "      <th>AgeQ</th>\n",
       "      <th>PrixQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vnon</td>\n",
       "      <td>Cl3</td>\n",
       "      <td>Gmas</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Ps</td>\n",
       "      <td>Ag1</td>\n",
       "      <td>Pr1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voui</td>\n",
       "      <td>Cl1</td>\n",
       "      <td>Gfem</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>Pc</td>\n",
       "      <td>Ag3</td>\n",
       "      <td>Pr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Voui</td>\n",
       "      <td>Cl3</td>\n",
       "      <td>Gfem</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Ps</td>\n",
       "      <td>Ag2</td>\n",
       "      <td>Pr1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voui</td>\n",
       "      <td>Cl1</td>\n",
       "      <td>Gfem</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>Ps</td>\n",
       "      <td>Ag3</td>\n",
       "      <td>Pr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vnon</td>\n",
       "      <td>Cl3</td>\n",
       "      <td>Gmas</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Ps</td>\n",
       "      <td>Ag3</td>\n",
       "      <td>Pr1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Surv Classe Genre   Age     Prix Port AgeQ PrixQ\n",
       "0  Vnon    Cl3  Gmas  22.0   7.2500   Ps  Ag1   Pr1\n",
       "1  Voui    Cl1  Gfem  38.0  71.2833   Pc  Ag3   Pr3\n",
       "2  Voui    Cl3  Gfem  26.0   7.9250   Ps  Ag2   Pr1\n",
       "3  Voui    Cl1  Gfem  35.0  53.1000   Ps  Ag3   Pr3\n",
       "4  Vnon    Cl3  Gmas  35.0   8.0500   Ps  Ag3   Pr1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discrétiser les variables quantitatives\n",
    "df[\"AgeQ\"]=pd.qcut(df.Age,3,labels=[\"Ag1\",\"Ag2\",\"Ag3\"])\n",
    "df[\"PrixQ\"]=pd.qcut(df.Prix,3,labels=[\"Pr1\",\"Pr2\",\"Pr3\"])\n",
    "# redéfinir les noms des modalités \n",
    "df[\"Surv\"]=df[\"Surv\"].cat.rename_categories([\"Vnon\",\"Voui\"])\n",
    "df[\"Classe\"]=df[\"Classe\"].cat.rename_categories([\"Cl1\",\"Cl2\",\"Cl3\"])\n",
    "df[\"Genre\"]=df[\"Genre\"].cat.rename_categories([\"Gfem\",\"Gmas\"])\n",
    "df[\"Port\"]=df[\"Port\"].cat.rename_categories([\"Pc\",\"Pq\",\"Ps\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surv      891\n",
       "Classe    891\n",
       "Genre     891\n",
       "Age       891\n",
       "Prix      891\n",
       "Port      891\n",
       "AgeQ      891\n",
       "PrixQ     891\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#petite vérification \n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Construction des échantillons d'entrainement et de test \n",
    "\n",
    "Le jeu de données (dit dataset) dont vous disposez constitue une **ressource précieuse**, il faut pouvoir l’utiliser à bon escient afin de pouvoir à la fois choisir un modèle et l'entraîner, mais aussi de pouvoir tester la qualité de ce modèle.\n",
    "\n",
    "**La première question à se poser est : est-ce qu’on va utiliser toutes les données d'exemple dont on dispose ?**\n",
    "\n",
    "En effet, s'il s’avère qu’on a beaucoup de données d’entraînement et/ou que l’algorithme d’apprentissage est lourd, il est possible qu’utiliser toutes les données prennent énormément de temps et/ou de ressources hardware. Dans ce cas, il faut naturellement échantillonner et ne récupérer qu’un petit pourcentage du dataset qui servira au travail de modélisation pour aller plus vite.\n",
    "Pour minimiser ce problème, la meilleure approche est de séparer dès le départ notre jeu de données en deux parties distinctes :\n",
    "- Le **training set**, qui va nous permettre d’entraîner notre modèle, et sera utilisé par l’algorithme d’apprentissage. \n",
    "- **Le testing set**, qui permet de mesurer l’erreur du modèle final sur des données qu’il n’a jamais vues. On va simplement passer ces données comme s'il s'agissait de données que l’on n'a encore jamais rencontrées (comme cela va se passer ensuite en pratique pour prédire de nouvelles données) et mesurer la performance de notre modèle sur ces données. \n",
    "\n",
    "En général, les données sont séparées avec les proportions suivantes : **80% pour le training set et 20% pour le testing set**. On peut cette fois utiliser la fonction de scikit-learn  `train_test_split` qui peut prendre en paramètre la proportion désirée. \n",
    "\n",
    "C'est donc dans cette optique que l'on va construire des indicatrices de variables descriptive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv_Vnon</th>\n",
       "      <th>Surv_Voui</th>\n",
       "      <th>Classe_Cl1</th>\n",
       "      <th>Classe_Cl2</th>\n",
       "      <th>Classe_Cl3</th>\n",
       "      <th>Genre_Gfem</th>\n",
       "      <th>Genre_Gmas</th>\n",
       "      <th>Port_Pc</th>\n",
       "      <th>Port_Pq</th>\n",
       "      <th>Port_Ps</th>\n",
       "      <th>AgeQ_Ag1</th>\n",
       "      <th>AgeQ_Ag2</th>\n",
       "      <th>AgeQ_Ag3</th>\n",
       "      <th>PrixQ_Pr1</th>\n",
       "      <th>PrixQ_Pr2</th>\n",
       "      <th>PrixQ_Pr3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Surv_Vnon  Surv_Voui  Classe_Cl1  Classe_Cl2  Classe_Cl3  Genre_Gfem  \\\n",
       "0          1          0           0           0           1           0   \n",
       "1          0          1           1           0           0           1   \n",
       "2          0          1           0           0           1           1   \n",
       "3          0          1           1           0           0           1   \n",
       "4          1          0           0           0           1           0   \n",
       "\n",
       "   Genre_Gmas  Port_Pc  Port_Pq  Port_Ps  AgeQ_Ag1  AgeQ_Ag2  AgeQ_Ag3  \\\n",
       "0           1        0        0        1         1         0         0   \n",
       "1           0        1        0        0         0         0         1   \n",
       "2           0        0        0        1         0         1         0   \n",
       "3           0        0        0        1         0         0         1   \n",
       "4           1        0        0        1         0         0         1   \n",
       "\n",
       "   PrixQ_Pr1  PrixQ_Pr2  PrixQ_Pr3  \n",
       "0          1          0          0  \n",
       "1          0          0          1  \n",
       "2          1          0          0  \n",
       "3          0          0          1  \n",
       "4          1          0          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construction des indicatrices\n",
    "df_q=df.drop([\"Age\",\"Prix\"],axis=1)\n",
    "df_q.head()\n",
    "# Indicatrices\n",
    "dc=pd.DataFrame(pd.get_dummies(df_q[[\"Surv\",\"Classe\",\"Genre\",\"Port\",\"AgeQ\",\"PrixQ\"]]))\n",
    "dc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Surv_Voui', 'Classe_Cl1', 'Classe_Cl2', 'Classe_Cl3', 'Genre_Gfem',\n",
       "       'Port_Pc', 'Port_Pq', 'Port_Ps', 'AgeQ_Ag1', 'AgeQ_Ag2', 'AgeQ_Ag3',\n",
       "       'PrixQ_Pr1', 'PrixQ_Pr2', 'PrixQ_Pr3', 'Age', 'Prix'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table des indicatrices\n",
    "df1=pd.get_dummies(df_q[[\"Surv\",\"Classe\",\"Genre\",\"Port\",\"AgeQ\",\"PrixQ\"]])\n",
    "# Une seule indicatrice par variable binaire\n",
    "df1=df1.drop([\"Surv_Vnon\",\"Genre_Gmas\"],axis=1)\n",
    "# Variables quantitatives\n",
    "df2=df[[\"Age\",\"Prix\"]]\n",
    "# Concaténation\n",
    "df_c=pd.concat([df1,df2],axis=1)\n",
    "# Vérification\n",
    "df_c.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des échantillons d'apprentissage et test\n",
    "# variables explicatives\n",
    "T=df_c.drop([\"Surv_Voui\"],axis=1)\n",
    "# Variable à modéliser\n",
    "z=df_c[\"Surv_Voui\"]\n",
    "# Extractions\n",
    "from sklearn.model_selection import train_test_split\n",
    "T_train,T_test,z_train,z_test=train_test_split(T,z,test_size=0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention**: l'échantillon test des données \"Titanic\" est relativement petit, l'estimation de l'erreur de prévision est donc sujette à caution car probablement de grande variance. Il suffit de changer l'initialisation (paramètre ` random_state`) et ré-exécuter les scripts pour s'en assurer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Les données générées \n",
    "Comme toute les bonnes librairies Sklearn à son générateur d'aléatoire. Nous pouvons donc générer des jeux de données plus ou moins aléatoire. Nous allons souvent nous appuyer sur le script `DataSet.py`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme des *K* plus proches voisins\n",
    "Les images des caractères sont codées par des variables  quantitatives. Le problème de reconnaissance de forme ou de discrimination est adapté à l'algorithme des  [$k$-plus proches voisins](https://fr.wikipedia.org/wiki/M%C3%A9thode_des_k_plus_proches_voisins). \n",
    "\n",
    "### Le principe \n",
    "\n",
    "Les k plus proches voisins est un algorithme de clustering, en d’autres termes c'est une [méthode non paramétrique](https://en.wikipedia.org/wiki/Nonparametric_statistics), elle permet d’identifier un pattern au sein des données et de regrouper les individus ayant des caractéristiques similaires. Il fait partie de ce que l'on nome [l'apprentissage supervisé](https://en.wikipedia.org/wiki/Supervised_learning), Sympathique et très utile pour les problèmes de segmentation (clients par exemple, mais pas que), par ailleurs cet algorithme s’applique sur des [variables quantitatives](https://fr.wikipedia.org/wiki/Variable_quantitative) et non [qualitative](https://fr.wikipedia.org/wiki/Variable_cat%C3%A9gorielle). \n",
    "Avant tout, il faut fixer le nombre de cluster que l’on souhaite obtenir. Disons 3 (2 c'est trop simple), on va tirer aléatoirement donc 3 individus. Ces 3 individus correspondent aux centres initiaux de nos 3 classes. Après on calcule la distance entre les autres individus et chaque centre. Il faut savoir qu'il y à plusieur façon de *\"mesurer une distance\"*, la méthode “classique” se base sur la distance euclidienne (si cela ne vous parle pas, voir le [notebook StatBasics.ipynb](https://github.com/bdallard/BD-IA/blob/master/StatBasics.ipynb)). Par ailleurs, le concept de [distance](https://fr.wikipedia.org/wiki/Distance_(math%C3%A9matiques)) est très intéressant.   \n",
    "\n",
    "\n",
    "### Les data \n",
    "\n",
    "Maintenant place à la mise en application. \n",
    "On dispose de la base de données d'apprentissage iris, **le jeu de données comprend 50 échantillons de chacune des trois espèces d'iris (Iris setosa, Iris virginica et Iris versicolor).  Quatre caractéristiques ont été mesurées à partir de chaque échantillon : la longueur et la largeur des sépales et des pétales, en centimètres.** \n",
    "\n",
    "### La mission \n",
    "\n",
    "Vous vous en doutez bien, notre mission c'est donc de faire des catégories de ces fleurs. Et le paramètre à optimiser pour contrôler [la complexité du modèle](https://fr.wikipedia.org/wiki/Analyse_de_la_complexit%C3%A9_des_algorithmes) est le nombre de voisin, `n_neighbors`. Les autres options sont décrites dans la [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). Go ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './dataset/iris.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b9d006ba7d4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# définition des nom de colône\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'sepal_length'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sepal_width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'petal_length'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'petal_width'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'class'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./dataset/iris.data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aurel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aurel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aurel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aurel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aurel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aurel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\aurel\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './dataset/iris.data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# définition des nom de colône \n",
    "names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "df = pd.read_csv('./dataset/iris.data', header=None, names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Première visualisation des data (previz)\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# configuration d'un style \n",
    "plt.style.use('fivethirtyeight')\n",
    "matplotlib.rc('font', family='DejaVu Sans') \n",
    "# plot\n",
    "sns.lmplot('sepal_length', 'sepal_width', data=df, hue='class', fit_reg=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autre plot\n",
    "sns.lmplot('petal_length', 'petal_width', data=df, hue='class', fit_reg=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# petite viz afin de voir la répartition, les éléments anormaux et/ou les particularités. \n",
    "import seaborn as sb \n",
    "sb.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des dataset de test et d'entrainement \n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np \n",
    "X = np.array(df.ix[:, 0:4]) \n",
    "y = np.array(df['class']) \n",
    "print('len de X et y : {}, {}'.format(len(X), len(y)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "print('** ** ** ** ** ** ** ** ** ** ** ** ** ** \\nTaille des vecteurs : \\nX_train {}, X_test {}, y_train {}, y_test {}'.format(len(X_train), len(X_test), len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du classifieur\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "# fit \n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimisation des hyperparamètres \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# création d'une liste de paramètres \n",
    "myList = list(range(1,64))\n",
    "neighbors = list(filter(lambda x: x % 2 != 0, myList))\n",
    "# stockage des valeurs \n",
    "cv_scores = []\n",
    "cv_scores_std = []\n",
    "\n",
    "# boucle de cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    cv_scores_std.append(scores.std())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcul de MSE \n",
    "MSE = [1 - x for x in cv_scores]\n",
    "# sélection du meilleur paramètre \n",
    "optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "# affichage \n",
    "print ('the optimal number of neighbors is {}'.format(optimal_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# évaluation de l'erreur de classification\n",
    "cv_scores_for_test = []\n",
    "# boucle de cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    cv_scores_for_test.append(accuracy_score(y_test, knn.predict(X_test)))\n",
    "    \n",
    "MSE_test = [1 - x for x in cv_scores_for_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour la variable [:2] \n",
    "cv_scores_for_test_0_2 = []\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train[:,:2], y_train)\n",
    "    cv_scores_for_test_0_2.append(accuracy_score(y_test, knn.predict(X_test[:,:2])))\n",
    "    \n",
    "MSE_test_0_2 = [1 - x for x in cv_scores_for_test_0_2]\n",
    "\n",
    "# pour la variable [2:4] \n",
    "cv_scores_for_test_2_4 = []\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train[:,2:4], y_train)\n",
    "    cv_scores_for_test_2_4.append(accuracy_score(y_test, knn.predict(X_test[:,2:4])))\n",
    "    \n",
    "MSE_test_2_4 = [1 - x for x in cv_scores_for_test_2_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le petit plot \n",
    "plt.clf()\n",
    "plt.plot(neighbors, MSE, label='k-fold')\n",
    "cv_low = [x - x_std for x, x_std in zip(MSE, cv_scores_std)]\n",
    "cv_hi = [x + x_std for x, x_std in zip(MSE, cv_scores_std)]\n",
    "plt.fill_between(neighbors, cv_low, cv_hi, label='k-fold(deviation)', alpha=0.3)\n",
    "plt.plot(neighbors, MSE_test, label='whole dataset and features')\n",
    "plt.plot(neighbors, MSE_test_0_2, label='features [:2]')\n",
    "plt.plot(neighbors, MSE_test_2_4, label='features [2:4]')\n",
    "plt.xlabel('number of neighbors K')\n",
    "plt.ylabel('misclassification error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# fonction afin de séléctionner l'ensemble d'entrainement \n",
    "def train(X_train, y_train):\n",
    "    # do nothing\n",
    "    return\n",
    "\n",
    "# fonction de prédiction \"from scratch\"\n",
    "def predict(X_train, y_train, x_test, k):\n",
    "    # calcul de la distance euclidienne simple\n",
    "    distances = [\n",
    "        [np.sqrt(np.sum(np.square(x_test - x_train))), i] \n",
    "        for i, x_train in enumerate(X_train)\n",
    "    ]        \n",
    "    # triage\n",
    "    distances = sorted(distances)\n",
    "    # définition des cibles  \n",
    "    targets = [y_train[distance[1]] for distance in distances[:k]]\n",
    "    # retourner les targets les plus proches \n",
    "    return collections.Counter(targets).most_common(1)[0][0]\n",
    "\n",
    "def k_nearest_neighbour(X_train, y_train, X_test, k):\n",
    "    train(X_train, y_train)    \n",
    "    # boucles \n",
    "    return [predict(X_train, y_train, x_test, k) for x_test in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = k_nearest_neighbour(X_train, y_train, X_test, 1)\n",
    "# transformation de la list en array \n",
    "pred = np.asarray(pred)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(\"\\nL'accuracy du classifieur est de : {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# évaluation de l'accuracy de l'algorithme sur les sous ensemble --> TRÈS IMPORTANT \n",
    "pred = k_nearest_neighbour(X_train[:,:2], y_train, X_test[:,:2], 1)\n",
    "# transformation de la list en array \n",
    "pred = np.asarray(pred)\n",
    "# accuracy\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(\"\\nL'accuracy du classifieur (sur les variables [:2]) est de : {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# région de décision \n",
    "from matplotlib import cm\n",
    "\n",
    "def label_to_int(labels):\n",
    "    return [list(set(labels)).index(y_value) for y_value in labels]\n",
    "\n",
    "# choisir 2 variables\n",
    "features_indexes = [0,1]\n",
    "\n",
    "# on plot les régions de decisions\n",
    "x_min, x_max = X[:, features_indexes[0]].min() - 1, X[:, features_indexes[0]].max() + 1\n",
    "y_min, y_max = X[:, features_indexes[1]].min() - 1, X[:, features_indexes[1]].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                     np.arange(y_min, y_max, 0.1))\n",
    "knn = KNeighborsClassifier(n_neighbors=13)\n",
    "knn.fit(X_train[:, features_indexes], y_train)\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = np.array(label_to_int(Z))\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, alpha=0.4, cmap=cm.jet)\n",
    "plt.scatter(X[:, features_indexes[0]], X[:, features_indexes[1]], c=[list(set(y)).index(y_value) for y_value in y], alpha=0.9, cmap=cm.jet)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La régression \n",
    "\n",
    "**Les deux problèmes types dans l'apprentissage automatique supervisé sont : la régression et la classification.** Nous avons vu l'algorithmes des k plus proches voisins plus haut voyons maintenant ce qu'est la régression.\n",
    "\n",
    "La régression est un ensemble de méthodes statistiques très utilisées pour analyser la relation d'une variable par rapport à une ou plusieurs autres. Il existe beaucoup de modèles de régression, le modèle le plus connu est le modèle de régression linéaire, très pratique et implémenté dans tous les logiciels de calculs. \n",
    "**Lorsque le modèle n'est pas linéaire, on peut effectuer une régression approchée par des algorithmes itératifs, on parle de régression non linéaire.**\n",
    "  \n",
    "\n",
    "### Le principe \n",
    "\n",
    "Les tâches dites de régression sont éffectuées dans le but de prédire une valeure continue, c'est à dire un nombre réeel (un flotant en informatique). Prédire un salaire en fonction de l'éducation, l'âge, le lieu de vie ou bien un le prix d'un loyer d'appartement en fonction de sa surface, sa localisation sont des exemples de modèle de régression.\n",
    "\n",
    "Comme expliqué dans le `notebook StatBasics` il existe plusieur type de régression, nous verrons uniquement dans ce cours les modèles linéaire, ridge et lasso. Voir le script `SklearnReg.py`\n",
    "\n",
    "\n",
    "### Les différences entre les modèles \n",
    "En effet, ce sont tous des modèles de régression mais il y a quand même des différences entre ces derniers. Les modèles de ridge et lasso sont des modèles mettant en jeux un **paramètre de régularisation**. On peut le faire varier et voir en quoi sa variation influe sur les données (test & entrainement). Ici afin d'illustrer la différence entre les modèles nous allons prendre comme metrics le score $R^2$ et voir son évolution par rapport à la taille des ensemble de tests et d'entrainement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.model_selection import learning_curve, KFold\n",
    "from DataSet import load_extended_boston\n",
    "import numpy as np\n",
    "\n",
    "def plot_learning_curve(est, X, y):\n",
    "    training_set_size, train_scores, test_scores = learning_curve(\n",
    "        est, X, y, train_sizes=np.linspace(.1, 1, 20), cv=KFold(20, shuffle=True, random_state=1))\n",
    "    estimator_name = est.__class__.__name__\n",
    "    line = plt.plot(training_set_size, train_scores.mean(axis=1), '--',\n",
    "                    label=\"training \" + estimator_name)\n",
    "    plt.plot(training_set_size, test_scores.mean(axis=1), '-',\n",
    "             label=\"test \" + estimator_name, c=line[0].get_color())\n",
    "    plt.xlabel(\"Taille de l'ensemble d'entrainement\")\n",
    "    plt.ylabel('Score (R^2)')\n",
    "    plt.ylim(0, 1.1)\n",
    "\n",
    "\n",
    "def plot_ridge_n_samples():\n",
    "    X, y = load_extended_boston()\n",
    "\n",
    "    plot_learning_curve(Ridge(alpha=1), X, y)\n",
    "    plot_learning_curve(LinearRegression(), X, y)\n",
    "    plt.legend(loc=(0, 1.05), ncol=2, fontsize=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ridge_n_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
